"""
    分布式训练

        分布式是指得系统或计算机任务被分布到多个独立的节点设备或计算设备上进行处理, 而不是集中在单个节点或计算机上

        分布式训练是一种通过将计算任务分发到多个计算设备上来加速训练过程的方式, 主要通过并行计算的方式, 将数据和计算任务分配到多个节点上(计算节点), 从而提供训练速度和处理大规模数据的能力

    
    分布式训练的方法

        数据并行(DataParrallel, DP)

            即在每个GPU上复制一份完整的模型, 然后每个GPU上训练的数据不同, 所有GPU训练完后合并起来
            要求是每个GPU不仅能够存放完整的模型, 而且还能满足该模型执行完整的训练
            

        模型并行

            分为流水并行、张量并行两种形式

            (1) 流水并行(PipelineParrallel)

                将模型按层拆分, 每个GPU包含部分的层, 保证能够正常训练, 然后数据按照流水线式输入到拆分的每个模型模块中进行训练

                优点: 不要求模型要加载并训练整个模型的能力

                缺点: 流水线式输入模型会造成很多GPU气泡, GPU利用率较低

            
            (2) 张量并行(TensorParrallel)

                将模型按层中的张量(权重张量)进行拆分, 每个GPU包含部分的张量, 保证能够正常训练, 然后数据按照流水线式输入到拆分的每个模块中进行训练

                优点: GPU利用率高, 没有流水并行那么多GPU气泡

                缺点: 计算难度复杂

            
        
    分布式训练策略

    
        原则: 尽可能地减少单机多卡的训练, 尽可能减少多机多卡的训练, 因为单机不同卡之间通信受限于带宽, 多机多卡之间的不同卡之间通信更是受限于带宽

        通信速度:  单机单卡通信速度 > 单机多卡间的通信速度 > 多机多卡间的通信速度

        训练策略的选择优先级:   单机单卡 > 单机多卡 > 多机多卡

        单卡可以完成模型的训练: 就使用DP

        单卡部分完成模型的训练: 就使用模型并行, 流水并行或张量并行, 为了提高GPU利用率, 优先使用张量并行

        混合策略(3D并行): 数据并行 + 流水并行 + 张量并行



                








"""