"""
    文本摘要任务

        输入长文本内容, 目标是针对该长文本生成一个简短精炼的摘要, 生成的摘要必须保证信息量充足、能够覆盖原始长文本的注意内容

    
    文本摘要任务分类

        若输入文档为单个, 则为单文档摘要任务; 若输入文本为多个, 则为多文档摘要任务
    
                
    本质: 文本摘要任务本质是text2text任务, 最好的模型架构就是seq2seq架构, 典型的模型就是T5


    评估指标: Rouge-1、Rouge-2、Rouge-L, 分别基于1-gram、2-gram以及最长公共子序列LCS来实现的

            模型预测为: 今天不错
            真实标签为: 今天太阳不错

            Rouge-1的计算方法如下:

                按照每个单词对预测结果和真实标签进行分割:   
                    
                    今-天-不-错

                    今-天-太-阳-不-错

                P(精确率): =  预测结果中的分词对在真实标签中个数 / 预测结果中分词总个数   =  4 / 4     因为模型预测的结果中有4个分词在真实标签中, 预测结果总共为4个分词

                Recall(召回率): = 预测结果中的分词对在真实标签中个数 / 真实标签中分词的总个数 = 4 / 6

                F1(F1分数): = 2 * (P * Recall) /  (P +  Recall)


            Rouge-2的计算方法如下:

                按照每两个单词对预测结果和真实标签进行分割:   
                    
                    今天-天不-不错

                    今天-天不-太阳-阳不-不错

                P(精确率): =  预测结果中的分词对在真实标签中个数 / 预测结果中分词总个数   =  2 / 3     因为模型预测的结果中有2个分词在真实标签中, 预测结果总共为3个分词

                Recall(召回率): = 预测结果中的分词对在真实标签中个数 / 真实标签中分词的总个数 = 2 / 5

                F1(F1分数): = 2 * (P * Recall) /  (P +  Recall)



            Rouge-L的计算方法如下:

                按照最长公共子序列进行分割 
                    
                    今天不错

                    今天太阳不错

                P(精确率): =  预测结果中的最长公共子序列中的分词个数 / 预测结果中最长公共子序列中分词总个数   =  4 / 4     因为模型预测的结果中最长公共子序列就是 "今天不错" 它有4个分词, 而预测中总共token数为4

                Recall(召回率): = 预测结果中的最长公共子序列中的分词个数 / 真实标签中分词的总个数 = 2 / 6                因为模型预测的结果中最长公共子序列就是 "今天不错" 它有4个分词, 而真实标签中也具有最长公共子序列 "今天不错", 但是它有6个token

                F1(F1分数): = 2 * (P * Recall) /  (P +  Recall)
            
                    

    应用: 给输入的文本取标题、总结内容等


"""